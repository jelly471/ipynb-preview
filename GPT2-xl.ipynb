{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a18d260-f326-460b-8449-f9766e546676",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time there lived a black cat. The cat belonged to a little girl called Katie. Every day, Katie\n",
      "would take her cat for a walk in the park.\n",
      "\n",
      "One day, as Katie and her cat were walking around, they saw a mean looking man. He said he wanted to\n",
      "take the cat, to which she replied \"This cat belongs to me, not you.\"\n",
      "\n",
      "The man replied \"Well, I'm going to take it anyway.\"\n",
      "\n",
      "Katie and her cat ran away, but the man followed them. Katie ran into a house, and the\n",
      "\n",
      "man followed her inside. Katie was scared, but she was able to get the cat out of the house.\n",
      "\n",
      "The man followed Katie into the woods, and Katie was able to get the cat out of the woods.\n",
      "\n",
      "Katie ran into a house, and the man followed her inside. Katie was scared, but she was able to get the\n",
      "\n",
      "cat out of the house. The man followed Katie into the woods, and Katie was able to get the cat out of the\n",
      "\n",
      "woods. Katie ran into a house, and the man followed her inside. Katie was scared, but she was able to get the\n",
      "\n",
      "cat out of the house. The man followed Katie into the woods, and Katie was able to get the cat out of the woods.\n",
      "\n",
      "Katie ran into a house, and the man followed her inside. Katie was scared, but she was able to get the\n",
      "\n",
      "cat out of the house. The man followed Katie into the woods, and Katie was able to get the cat out of the woods.\n",
      "\n",
      "Katie ran into a house, and the man followed her inside. Katie was scared, but she was able to get the\n",
      "\n",
      "cat out of the house. The man followed Katie into the woods, and Katie was able to get the cat out of the woods.\n",
      "\n",
      "Katie ran into a house, and the man followed her inside. Katie was scared, but she was able to get the\n",
      "\n",
      "cat out of the house. The man followed Katie into the woods, and Katie was able to get the cat out of the woods.\n",
      "\n",
      "Katie ran into a house, and the man followed her inside. Katie was scared, but she was able to get the\n",
      "\n",
      "cat out of the house. The man followed Katie into the woods, and Katie was able to get the cat out of the woods.\n",
      "\n",
      "Katie ran into a house, and the man followed her inside. Katie was scared, but she was able to get the\n",
      "\n",
      "cat out of the house. The man followed Katie into the woods, and Katie was able to get the cat out of the woods.\n",
      "\n",
      "Katie ran into a house, and the man followed her inside. Katie was scared, but she was able to get the\n",
      "\n",
      "cat out of the house. The man followed Katie into the woods, and Katie was able to get the cat out of the woods.\n",
      "\n",
      "Katie ran into a house, and the man followed her inside. Katie was scared, but she was able to get the\n",
      "\n",
      "cat out of the house. The man followed Katie into the woods, and Katie was able to get the cat out of the woods.\n",
      "\n",
      "Katie ran into a house, and the man followed her inside. Katie was scared, but she was able to get the\n",
      "\n",
      "cat out of the house. The man followed Katie into the woods, and Katie was able to get the cat out of the woods.\n",
      "\n",
      "Katie ran into a house, and the man followed her inside. Katie was scared, but she was able to get the\n",
      "\n",
      "cat out of the house. The man followed Katie into the woods, and Katie was able to get the cat out of the woods.\n",
      "\n",
      "Katie ran into a house, and the man followed her inside. Katie was scared, but she was able to get the\n",
      "\n",
      "cat out of the house. The man followed Katie into the woods, and Katie was able to get the cat out of the woods.\n",
      "\n",
      "Katie ran into a house, and the man followed her inside. Katie was scared, but she was able to get the\n",
      "\n",
      "cat out of the house. The man followed Katie into the woods, and Katie was able to get the cat out of the woods.\n",
      "\n",
      "Katie ran into a house, and the man followed her inside. Katie was scared, but she was able to get the\n",
      "\n",
      "cat out of the house. The man followed Katie into the woods, and Katie was able to get the cat out of the woods.\n",
      "\n",
      "Katie ran into a house, and the man followed her inside. Katie was scared, but she was able to get the\n",
      "\n",
      "cat out of the house. The man followed Katie into the woods, and Katie was able to get\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained('./gpt2_xl')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./gpt2_xl\")\n",
    "\n",
    "prompt = \"\"\"Once upon a time there lived a black cat. The cat belonged to a little girl called Katie. Every day, Katie\n",
    "would take her cat for a walk in the park.\n",
    "\n",
    "One day, as Katie and her cat were walking around, they saw a mean looking man. He said he wanted to\n",
    "take the cat, to which she replied \"This cat belongs\"\"\"\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Generate completion\n",
    "output = model.generate(input_ids, max_length = 1000, num_beams=1)\n",
    "\n",
    "# Decode the completion\n",
    "output_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# Print the generated text\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bab4e8fb-2891-4252-b728-cbddc02202d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in an ancient house, there lived a girl named Lily. She loved to decorate her room with pretty things. One\n",
      "day, she found a big box in the attic. She opened it and saw many shiny decorations. Lily was very happy and decided to use\n",
      "them in her room.\n",
      "\n",
      "As Lily was decorating her room, the sky outside became dark. There was a loud thunderstorm. Lily was scared and\n",
      "\n",
      "thought that the thunderstorm was coming. She ran to the window and looked out. The sky was dark and the rain was\n",
      "\n",
      "raining. Lily was very sad and thought that she would never see the sky again.\n",
      "\n",
      "Suddenly, a bright light appeared in the sky. Lily was so happy and thought that it was a sign from God.\n",
      "\n",
      "She ran to the window and looked out. The sky was bright and the rain stopped. Lily was so happy and thought that\n",
      "\n",
      "God had answered her prayers.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that she would never see the sky again.\n",
      "\n",
      "Lily was so happy and thought that\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained('./gpt2_xl')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./gpt2_xl\")\n",
    "\n",
    "prompt = \"\"\"Once upon a time, in an ancient house, there lived a girl named Lily. She loved to decorate her room with pretty things. One\n",
    "day, she found a big box in the attic. She opened it and saw many shiny decorations. Lily was very happy and decided to use\n",
    "them in her room.\n",
    "\n",
    "As Lily was decorating her room, the sky outside became dark. There was a loud\"\"\"\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Generate completion\n",
    "output = model.generate(input_ids, max_length = 1000, num_beams=1)\n",
    "\n",
    "# Decode the completion\n",
    "output_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# Print the generated text\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0a167ec-927c-419f-b566-77f920670cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting transformers\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/62/c0/810e741a6244c0f004be40ccb96486d072f042eabbd4d7e8aa02b81ca1eb/transformers-4.44.0-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock (from transformers)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ae/f0/48285f0262fe47103a4a45972ed2f9b93e4c80b8fd609fa98da78b2a5706/filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/0b/05/31b21998f68c31e7ffcc27ff08531fb9af5506d765ce8d661fb0036e6918/huggingface_hub-0.24.5-py3-none-any.whl (417 kB)\n",
      "Collecting numpy>=1.17 (from transformers)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c2/da/3d8debb409bc97045b559f408d2b8cefa6a077a73df14dbf4d8780d976b1/numpy-2.0.1-cp312-cp312-macosx_14_0_arm64.whl (5.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/9b/f2/c6182095baf0a10169c34e87133a8e73b2e816a80035669b1278e927685e/regex-2024.7.24-cp312-cp312-macosx_11_0_arm64.whl (279 kB)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/3a/a1/d99aa8d10fa8d82276ee2aaa87afd0a6b96e69c128eaa9f93524b52c5276/safetensors-0.4.4-cp312-cp312-macosx_11_0_arm64.whl (381 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/74/d1/f4e1e950adb36675dfd8f9d0f4be644f3f3aaf22a5677a4f5c81282b662e/tokenizers-0.19.1-cp312-cp312-macosx_11_0_arm64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tqdm>=4.27 (from transformers)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/48/5d/acf5905c36149bbaec41ccf7f2b68814647347b72075ac0b1fe3022fdc73/tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.23.2->transformers)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/5e/44/73bea497ac69bafde2ee4269292fa3b41f1198f4bb7bbaaabde30ad29d4a/fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub<1.0,>=0.23.2->transformers)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/26/9f/ad63fc0248c5379346306f8668cda6e2e2e9c95e01216d2b8ffd9ff037d0/typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (2024.7.4)\n",
      "Installing collected packages: typing-extensions, tqdm, safetensors, regex, numpy, fsspec, filelock, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed filelock-3.15.4 fsspec-2024.6.1 huggingface-hub-0.24.5 numpy-2.0.1 regex-2024.7.24 safetensors-0.4.4 tokenizers-0.19.1 tqdm-4.66.5 transformers-4.44.0 typing-extensions-4.12.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11067f19-467d-4d39-81b5-139d08be7d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting torch\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c7/87/489ebb234e75760e06fa4789fa6d4e13c125beefa1483ce35c9e43dcd395/torch-2.4.0-cp312-none-macosx_11_0_arm64.whl (62.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Collecting sympy (from torch)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c1/f9/6845bf8fca0eaf847da21c5d5bc6cd92797364662824a11d3f836423a1a5/sympy-1.13.2-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting networkx (from torch)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/38/e9/5f72929373e1a0e8d142a130f3f97e6ff920070f87f91c4e13e40e0fba5a/networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (72.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/43/e3/7d92a15f894aa0c9c4b49b8ee9ac9850d6e63b03c9c32c0367a13ae62209/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, sympy, networkx, torch\n",
      "Successfully installed mpmath-1.3.0 networkx-3.3 sympy-1.13.2 torch-2.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f4915f-0aee-434e-9246-471a1ec76910",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
